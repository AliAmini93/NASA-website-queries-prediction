import pandas as pd
import numpy as np
from keras.models import Sequential
from keras.layers import Dense
#from keras.layers.advanced_activations import LeakyReLU
import keras 
from keras import backend as K
# Code to read csv file into Colaboratory:
!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
def plot_history(net_history):
    history = net_history.history
    import matplotlib.pyplot as plt
    losses = history['loss']
    val_losses = history['val_loss']
    
    MAPE= history['mean_absolute_percentage_error']
    val_MAPE = history['val_mean_absolute_percentage_error']
    
     
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.semilogx(losses)
    plt.semilogx(val_losses)
    plt.legend(['loss', 'val_loss'])
    
    
    plt.figure()
    plt.xlabel('Epochs')
    plt.ylabel('mape')
    plt.plot(MAPE)
    plt.plot(val_MAPE)
    plt.legend(['mean_absolute_percentage_error', 'val_mean_absolute_percentage_error'])
    
# Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)
file_list = drive.ListFile({'q': "'1UqODgPTwZ0Sjp8-vjAVePnHlBnqV8SzP' in parents and trashed=false"}).GetList()
for file1 in file_list:
  print('title: %s, id: %s' % (file1['title'], file1['id']))
  
train_downloaded = drive.CreateFile({'id': '1T5-3QyfH215GFyT34VAiThbjtDA3Dwl0'})
train_downloaded.GetContentFile('trainset.csv')
test_downloaded = drive.CreateFile({'id': '1XDuiFGysKQFfrl7dcUFcQGVr-sSA3C8x'})
test_downloaded.GetContentFile('testset.csv') 

dataframe = pd.read_csv('trainset.csv', delim_whitespace=False,header=None)
trainset = dataframe.values
dataframe = pd.read_csv('testset.csv', delim_whitespace=False,header=None)
testset = dataframe.values
X_train = trainset[:,0:5]
Y_train = trainset[:,5]
X_test = testset[:,0:5]
Y_test = testset[:,5]

myModel=Sequential()
myModel.add(Dense(10, input_shape=(5,), activation='relu', use_bias=True))
myModel.add(Dense(1,use_bias=True, activation='relu'))

myModel.summary()
myModel.compile(optimizer=keras.optimizers.Adam(), loss="mse", metrics =['mape'])
network_history = myModel.fit(X_train, Y_train, epochs=95, batch_size=256,validation_split= 0.0000000001)
plot_history(network_history)
test_loss, test_mape = myModel.evaluate(X_test, Y_test)
weights = [layer.get_weights() for layer in myModel.layers]
v=weights[0][0]
v=v.reshape(50,1)
v=v.transpose()
v0=weights[0][1]
v0=v0[np.newaxis, :].T
v0=v0.transpose()
w= weights[1][0]
w=w.transpose()
w0=weights[1][1]
w0=w0[np.newaxis, :].T
weight=[]
weight=np.concatenate((v, v0), axis=None)
weight=np.concatenate((weight, w), axis=None)
weight=np.concatenate((weight, w0), axis=None)
weight=weight[np.newaxis, :].T
weight= weight.transpose()